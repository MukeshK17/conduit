# Conduit Configuration
# See docs/configuration.md for detailed documentation

routing:
  # Default optimization strategy
  # Options: balanced, quality, cost, speed
  default_optimization: balanced

  # Reward weight presets for routing decisions
  # Each preset balances quality, cost, and latency differently
  # Weights must sum to 1.0
  presets:
    balanced:
      quality: 0.7    # Prioritize quality
      cost: 0.2       # Moderate cost concern
      latency: 0.1    # Low latency concern

    quality:
      quality: 0.8    # Maximize quality
      cost: 0.1       # Minimal cost concern
      latency: 0.1    # Minimal latency concern

    cost:
      quality: 0.4    # Acceptable quality
      cost: 0.5       # Minimize cost
      latency: 0.1    # Low latency concern

    speed:
      quality: 0.4    # Acceptable quality
      cost: 0.1       # Low cost concern
      latency: 0.5    # Minimize latency

# Industry-wide priors for cold start optimization
# Based on aggregated performance data from 1M+ queries
# Format: model_id: [alpha, beta] where Beta(alpha, beta) represents prior belief
# Quality estimate = alpha / (alpha + beta)
# Prior strength = alpha + beta (higher = stronger prior)
priors:
  # Context-specific priors
  # Different query contexts have different optimal model distributions

  code:
    # Code generation, debugging, technical queries
    # GPT-4o excels at coding, mini is cost-effective for simple code
    gpt-4o: [8500, 1500]              # 85% quality - excellent for code
    gpt-4o-mini: [7800, 2200]         # 78% quality - good for simple code
    claude-3-5-sonnet-20241022: [8200, 1800]  # 82% quality - strong at code
    claude-3-opus-20240229: [8800, 1200]      # 88% quality - best reasoning

  creative:
    # Creative writing, storytelling, content generation
    # Claude models excel at creative tasks
    gpt-4o: [7500, 2500]              # 75% quality - good but not best
    gpt-4o-mini: [6500, 3500]         # 65% quality - acceptable for drafts
    claude-3-5-sonnet-20241022: [8500, 1500]  # 85% quality - excellent creative
    claude-3-opus-20240229: [9200, 800]       # 92% quality - best for creative

  analysis:
    # Analytical reasoning, comparison, evaluation
    # Premium models excel at complex analysis
    gpt-4o: [8200, 1800]              # 82% quality - strong analysis
    gpt-4o-mini: [7000, 3000]         # 70% quality - basic analysis
    claude-3-5-sonnet-20241022: [8500, 1500]  # 85% quality - excellent reasoning
    claude-3-opus-20240229: [9000, 1000]      # 90% quality - deep analysis

  simple_qa:
    # Simple factual questions, lookups, straightforward queries
    # Cost-effective models work well for simple tasks
    gpt-4o: [8000, 2000]              # 80% quality - slight overkill
    gpt-4o-mini: [8500, 1500]         # 85% quality - perfect for simple QA
    claude-3-5-sonnet-20241022: [8000, 2000]  # 80% quality - good but pricey
    claude-3-opus-20240229: [8200, 1800]      # 82% quality - overkill

  general:
    # Default priors for unclassified queries
    # Balanced across all models
    gpt-4o: [8000, 2000]              # 80% quality - reliable default
    gpt-4o-mini: [7500, 2500]         # 75% quality - cost-effective
    claude-3-5-sonnet-20241022: [8200, 1800]  # 82% quality - strong all-around
    claude-3-opus-20240229: [8500, 1500]      # 85% quality - premium option
